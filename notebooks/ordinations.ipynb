{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7109ac01",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb6ba8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install bernn[full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12488c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d27f777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_experiment_data(exp_path):\n",
    "    \"\"\"Load experiment data and results.\"\"\"\n",
    "    # Load data\n",
    "    with open(os.path.join(exp_path, 'data.pkl'), 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    # Load uniques\n",
    "    with open(os.path.join(exp_path, 'uniques.pkl'), 'rb') as f:\n",
    "        uniques = pickle.load(f)\n",
    "    \n",
    "    # Load feature importances\n",
    "    xgb_importance = pd.read_csv(os.path.join(exp_path, 'ords_filtered/xgboost_feature_importance.csv'))\n",
    "    shap_importance = pd.read_csv(os.path.join(exp_path, 'ords_filtered/shap_feature_importance.csv'))\n",
    "    \n",
    "    return data, uniques, xgb_importance, shap_importance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8de2d98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ordination(X, labels, batches, title, feature_type='all'):\n",
    "    \"\"\"Plot PCA and LDA ordinations.\"\"\"\n",
    "    # PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    pcs = pca.fit_transform(X)\n",
    "    pcs_df = pd.DataFrame(data=pcs, columns=['PC1', 'PC2'])\n",
    "    pcs_df['label'] = labels\n",
    "    pcs_df['batch'] = batches\n",
    "    \n",
    "    # LDA\n",
    "    lda = LDA(n_components=2)\n",
    "    lds = lda.fit_transform(X, labels)\n",
    "    lds_df = pd.DataFrame(data=lds, columns=['LD1', 'LD2'])\n",
    "    lds_df['label'] = labels\n",
    "    lds_df['batch'] = batches\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 20))\n",
    "    \n",
    "    # PCA by label\n",
    "    sns.scatterplot(data=pcs_df, x='PC1', y='PC2', hue='label', ax=axes[0,0])\n",
    "    axes[0,0].set_title(f'PCA by Label ({feature_type} features)\\nExplained variance: {pca.explained_variance_ratio_.sum():.2%}')\n",
    "    \n",
    "    # PCA by batch\n",
    "    sns.scatterplot(data=pcs_df, x='PC1', y='PC2', hue='batch', ax=axes[0,1])\n",
    "    axes[0,1].set_title(f'PCA by Batch ({feature_type} features)')\n",
    "    \n",
    "    # LDA by label\n",
    "    sns.scatterplot(data=lds_df, x='LD1', y='LD2', hue='label', ax=axes[1,0])\n",
    "    axes[1,0].set_title(f'LDA by Label ({feature_type} features)')\n",
    "    \n",
    "    # LDA by batch\n",
    "    sns.scatterplot(data=lds_df, x='LD1', y='LD2', hue='batch', ax=axes[1,1])\n",
    "    axes[1,1].set_title(f'LDA by Batch ({feature_type} features)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbf0b324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_all_ordinations(data, uniques, xgb_importance, shap_importance, threshold=0):\n",
    "    \"\"\"Create ordination plots for all features, XGBoost features, and SHAP features.\"\"\"\n",
    "    # All features\n",
    "    fig_all = plot_ordination(\n",
    "        data['inputs']['all'],\n",
    "        data['labels']['all'],\n",
    "        data['batches']['all'],\n",
    "        'All Features'\n",
    "    )\n",
    "    \n",
    "    # XGBoost features\n",
    "    xgb_features = xgb_importance[xgb_importance['importance'] > threshold]['feature'].tolist()\n",
    "    fig_xgb = plot_ordination(\n",
    "        data['inputs']['all'][xgb_features],\n",
    "        data['labels']['all'],\n",
    "        data['batches']['all'],\n",
    "        'XGBoost Features'\n",
    "    )\n",
    "    \n",
    "    # SHAP features\n",
    "    shap_features = shap_importance[shap_importance['shap_importance'] > threshold]['feature'].tolist()\n",
    "    fig_shap = plot_ordination(\n",
    "        data['inputs']['all'][shap_features],\n",
    "        data['labels']['all'],\n",
    "        data['batches']['all'],\n",
    "        'SHAP Features'\n",
    "    )\n",
    "    \n",
    "    return fig_all, fig_xgb, fig_shap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cc06e1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/multi/mz10/rt10/ms2/200spd/thr0.0/all/BPatients-b15-b14-b13-b12-b11-b10-b9-b8-b7-b6-b5-b4-b3-b2-b1_binary0_-1_gkf1_ovr0_mz0-10000rt0-320_na_h/xgboost/data.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[32m      2\u001b[39m exp_path = \u001b[33m'\u001b[39m\u001b[33mresults/multi/mz10/rt10/ms2/200spd/thr0.0/all/BPatients-b15-b14-b13-b12-b11-b10-b9-b8-b7-b6-b5-b4-b3-b2-b1_binary0_-1_gkf1_ovr0_mz0-10000rt0-320_na_h/xgboost\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m data, uniques, xgb_importance, shap_importance = load_experiment_data(exp_path)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Create visualizations\u001b[39;00m\n\u001b[32m      6\u001b[39m fig_all, fig_xgb, fig_shap = visualize_all_ordinations(data, uniques, xgb_importance, shap_importance)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mload_experiment_data\u001b[39m\u001b[34m(exp_path)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load experiment data and results.\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os.path.join(exp_path, \u001b[33m'\u001b[39m\u001b[33mdata.pkl\u001b[39m\u001b[33m'\u001b[39m), \u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      5\u001b[39m     data = pickle.load(f)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Load uniques\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:326\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    321\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    324\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, *args, **kwargs)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'results/multi/mz10/rt10/ms2/200spd/thr0.0/all/BPatients-b15-b14-b13-b12-b11-b10-b9-b8-b7-b6-b5-b4-b3-b2-b1_binary0_-1_gkf1_ovr0_mz0-10000rt0-320_na_h/xgboost/data.pkl'"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "exp_path = 'results/multi/mz10/rt10/ms2/200spd/thr0.0/all/BPatients-b15-b14-b13-b12-b11-b10-b9-b8-b7-b6-b5-b4-b3-b2-b1_binary0_-1_gkf1_ovr0_mz0-10000rt0-320_na_h/xgboost'\n",
    "data, uniques, xgb_importance, shap_importance = load_experiment_data(exp_path)\n",
    "\n",
    "# Create visualizations\n",
    "fig_all, fig_xgb, fig_shap = visualize_all_ordinations(data, uniques, xgb_importance, shap_importance)\n",
    "\n",
    "# Save figures\n",
    "fig_all.savefig('ordinations_all_features.png')\n",
    "fig_xgb.savefig('ordinations_xgboost_features.png')\n",
    "fig_shap.savefig('ordinations_shap_features.png') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
