digraph {
	graph [size="12,12"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140468757983248 [label="
 (17)" fillcolor=darkolivegreen1]
	140468407369584 [label="MeanBackward1
--------------------------
dim           :       (0,)
keepdim       :      False
self_sym_numel:      32198
self_sym_sizes: (1894, 17)"]
	140468407361712 -> 140468407369584
	140468407361712 -> 140468757389184 [dir=none]
	140468757389184 [label="mat1
 (1894, 64)" fillcolor=orange]
	140468407361712 -> 140468758986432 [dir=none]
	140468758986432 [label="mat2
 (64, 17)" fillcolor=orange]
	140468407361712 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (1894, 64)
mat1_sym_strides:        (64, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :       (64, 17)
mat2_sym_strides:        (1, 64)"]
	140468407364016 -> 140468407361712
	140468759554352 [label="linear2.0.bias
 (17)" fillcolor=lightblue]
	140468759554352 -> 140468407364016
	140468407364016 [label=AccumulateGrad]
	140468407367712 -> 140468407361712
	140468407367712 -> 140468758211904 [dir=none]
	140468758211904 [label="result
 (1894, 64)" fillcolor=orange]
	140468407367712 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140468407367424 -> 140468407367712
	140468407367424 -> 140468756779536 [dir=none]
	140468756779536 [label="result1
 (1894, 64)" fillcolor=orange]
	140468407367424 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140468407366464 -> 140468407367424
	140468407366464 -> 140468758980352 [dir=none]
	140468758980352 [label="input
 (1894, 64)" fillcolor=orange]
	140468407366464 -> 140468756775536 [dir=none]
	140468756775536 [label="result1
 (64)" fillcolor=orange]
	140468407366464 -> 140468756787376 [dir=none]
	140468756787376 [label="result2
 (64)" fillcolor=orange]
	140468407366464 -> 140468762366000 [dir=none]
	140468762366000 [label="running_mean
 (64)" fillcolor=orange]
	140468407366464 -> 140468759556752 [dir=none]
	140468759556752 [label="running_var
 (64)" fillcolor=orange]
	140468407366464 -> 140468759550272 [dir=none]
	140468759550272 [label="weight
 (64)" fillcolor=orange]
	140468407366464 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	140468407366848 -> 140468407366464
	140468407366848 -> 140468757383104 [dir=none]
	140468757383104 [label="mat1
 (1894, 6443)" fillcolor=orange]
	140468407366848 -> 140469877982128 [dir=none]
	140469877982128 [label="mat2
 (6443, 64)" fillcolor=orange]
	140468407366848 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :   (1894, 6443)
mat1_sym_strides:      (6443, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (6443, 64)
mat2_sym_strides:      (1, 6443)"]
	140468407358640 -> 140468407366848
	140468759546272 [label="linear1.0.bias
 (64)" fillcolor=lightblue]
	140468759546272 -> 140468407358640
	140468407358640 [label=AccumulateGrad]
	140468407362960 -> 140468407366848
	140468407362960 -> 140468759544512 [dir=none]
	140468759544512 [label="mat1
 (1894, 1472)" fillcolor=orange]
	140468407362960 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :   (1894, 1472)
mat1_sym_strides:             ()
mat2            :           None
mat2_sym_sizes  :   (1472, 6443)
mat2_sym_strides:      (1, 1472)"]
	140468407424944 -> 140468407362960
	140468759553392 [label="
 (6443)" fillcolor=lightblue]
	140468759553392 -> 140468407424944
	140468407424944 [label=AccumulateGrad]
	140468407369488 -> 140468407362960
	140468407369488 [label=TBackward0]
	140468407425472 -> 140468407369488
	140468751734304 [label="
 (6443, 1472)" fillcolor=lightblue]
	140468751734304 -> 140468407425472
	140468407425472 [label=AccumulateGrad]
	140468407359312 -> 140468407366848
	140468407359312 [label=TBackward0]
	140468407359744 -> 140468407359312
	140468759546672 [label="linear1.0.weight
 (64, 6443)" fillcolor=lightblue]
	140468759546672 -> 140468407359744
	140468407359744 [label=AccumulateGrad]
	140468407364544 -> 140468407366464
	140468759550272 [label="linear1.1.weight
 (64)" fillcolor=lightblue]
	140468759550272 -> 140468407364544
	140468407364544 [label=AccumulateGrad]
	140468407365216 -> 140468407366464
	140468759549072 [label="linear1.1.bias
 (64)" fillcolor=lightblue]
	140468759549072 -> 140468407365216
	140468407365216 [label=AccumulateGrad]
	140468407361808 -> 140468407361712
	140468407361808 [label=TBackward0]
	140468407361376 -> 140468407361808
	140468759557392 [label="linear2.0.weight
 (17, 64)" fillcolor=lightblue]
	140468759557392 -> 140468407361376
	140468407361376 [label=AccumulateGrad]
	140468407369584 -> 140468757983248
}
